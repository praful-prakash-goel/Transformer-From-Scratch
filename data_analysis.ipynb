{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af16bf0e-d1fe-43ea-8904-94612be0113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcaad267-c9ec-4379-9c23-6925242d852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 32\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd55bb88-180d-4c2b-88c6-db6d82796658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175621, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours !\n",
       "2                    Run!               Courez !\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             Ça alors !"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('eng_to_french.zip')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2aef62ed-a303-4611-bfa2-0c2db5a85496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eng_text = df['English words/sentences'].tolist()\n",
    "french_text = df['French words/sentences'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9e052cf-e777-4ba2-a81d-784f144bd7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> English Vocabulary: \n",
      "[' ', '!', '\"', '$', '%', '&', \"'\", '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '\\xad', 'º', 'ç', 'é', 'ö', 'ú', 'а', '–', '—', '‘', '’', '₂', '€']\n",
      "Size: 91\n",
      ">> French Vocabulary: \n",
      "[' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Â', 'Ç', 'É', 'Ê', 'Ô', 'à', 'á', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ö', 'ù', 'û', 'œ', 'С', '\\u2009', '\\u200b', '–', '‘', '’', '…', '\\u202f', '‽', '₂']\n",
      "Size: 113\n"
     ]
    }
   ],
   "source": [
    "eng_chars = set()\n",
    "\n",
    "for sent in eng_text:\n",
    "    for ch in sent:\n",
    "        if ch not in eng_chars:\n",
    "            eng_chars.add(ch)\n",
    "\n",
    "fr_chars = set()\n",
    "for sent in french_text:\n",
    "    for ch in sent:\n",
    "        if ch not in fr_chars:\n",
    "            fr_chars.add(ch)\n",
    "\n",
    "eng_chars = sorted(list(eng_chars))\n",
    "fr_chars = sorted(list(fr_chars))\n",
    "\n",
    "vocab_size_eng = len(eng_chars)\n",
    "vocab_size_fr = len(fr_chars)\n",
    "\n",
    "print(\">> English Vocabulary: \")\n",
    "print(eng_chars)\n",
    "print(f\"Size: {vocab_size_eng}\")\n",
    "\n",
    "print(\">> French Vocabulary: \")\n",
    "print(fr_chars)\n",
    "print(f\"Size: {vocab_size_fr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92aa9f92-ff9e-4366-8a59-b93dec1c6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer:\n",
    "    def __init__(self, chars, specials=('<pad>', '<unk>', '<bos>', '<eos>')):\n",
    "        self.specials = list(specials)\n",
    "        self.chars = self.specials + sorted(set(chars))\n",
    "        self.stoi = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.itos = {i: ch for i, ch in enumerate(self.chars)}\n",
    "\n",
    "        self.pad = self.stoi['<pad>']\n",
    "        self.unk = self.stoi['<unk>']\n",
    "        self.bos = self.stoi['<bos>']\n",
    "        self.eos = self.stoi['<eos>']\n",
    "\n",
    "    def encode(self, s, add_bos=True, add_eos=True):\n",
    "        ids = [self.stoi.get(ch, self.unk) for ch in s]\n",
    "        if add_bos:\n",
    "            ids = [self.bos] + ids\n",
    "        if add_eos:\n",
    "            ids = ids + [self.eos]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids, remove_specials=True):\n",
    "        if remove_specials:\n",
    "            ids = [i for i in ids if i not in (self.pad, self.bos, self.eos)]\n",
    "        return ''.join([self.itos[i] for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2f216a7-44e9-4670-84b2-32fb15302461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 36, 63, 63, 4, 74, 62, 59, 72, 59, 5, 3]\n",
      "<bos>Hii there!<eos>\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = CharTokenizer(eng_chars)\n",
    "fr_tokenizer = CharTokenizer(fr_chars)\n",
    "print(eng_tokenizer.encode('Hii there!'))\n",
    "print(eng_tokenizer.decode(eng_tokenizer.encode('Hii there!'), remove_specials=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3709d67-d7be-4730-a5bf-46a5d0647fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_data = [eng_tokenizer.encode(sent) for sent in eng_text]\n",
    "fr_data = [fr_tokenizer.encode(sent) for sent in french_text]\n",
    "\n",
    "train_len = int(0.9 * len(eng_data))\n",
    "eng_data_train, eng_data_val = eng_data[:train_len], eng_data[train_len:]\n",
    "fr_data_train, fr_data_val = fr_data[:train_len], fr_data[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e35f2764-dcc7-4412-a49a-6bf8ca98ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_and_padding(split='train'):\n",
    "    eng_data = eng_data_train if split == 'train' else eng_data_val\n",
    "    fr_data = fr_data_train if split == 'train' else fr_data_val\n",
    "\n",
    "    def pad(ids, max_len, pad_id):\n",
    "        ids = ids[:max_len]\n",
    "        return ids + [pad_id] * (max_len - len(ids))\n",
    "\n",
    "    # sample random idxs for batching\n",
    "    idxs = torch.randint(len(eng_data) - context_length, (batch_size,))\n",
    "    \n",
    "    # apply padding and create batch\n",
    "    src_batch = torch.stack([\n",
    "        torch.tensor(pad(eng_data[i], context_length, eng_tokenizer.pad), dtype=torch.long)\n",
    "        for i in idxs\n",
    "    ])\n",
    "    tgt_batch = torch.stack([\n",
    "        torch.tensor(pad(fr_data[i], context_length, fr_tokenizer.pad), dtype=torch.long)\n",
    "        for i in idxs\n",
    "    ])\n",
    "    \n",
    "    # create padding mask\n",
    "    src_mask = src_batch != eng_tokenizer.pad\n",
    "    tgt_mask = tgt_batch != fr_tokenizer.pad\n",
    "\n",
    "    return src_batch, tgt_batch, src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e694a0e-d59d-4aeb-ab9e-33412086de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_batch, tgt_batch, src_mask, tgt_mask = get_batch_and_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ddfc55a-8646-444f-9c33-c5ed8dc8adc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somebody touched me.\n"
     ]
    }
   ],
   "source": [
    "print(eng_tokenizer.decode(src_batch[1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e56ab46b-9c82-4675-9664-71130bf2b116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelqu'un m'a touché.\n"
     ]
    }
   ],
   "source": [
    "print(fr_tokenizer.decode(tgt_batch[1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c7540-8d3b-4301-99cd-9cbec7f11536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
